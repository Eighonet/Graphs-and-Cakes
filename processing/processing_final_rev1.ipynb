{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly-express\n",
      "  Using cached plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Requirement already satisfied: scipy>=0.18 in /home/user/conda/lib/python3.7/site-packages (from plotly-express) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/user/conda/lib/python3.7/site-packages (from plotly-express) (1.20.1)\n",
      "Collecting plotly>=4.1.0\n",
      "  Using cached plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Collecting patsy>=0.5\n",
      "  Using cached patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Collecting statsmodels>=0.9.0\n",
      "  Using cached statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /home/user/conda/lib/python3.7/site-packages (from plotly-express) (1.2.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user/conda/lib/python3.7/site-packages (from pandas>=0.20.0->plotly-express) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/user/conda/lib/python3.7/site-packages (from pandas>=0.20.0->plotly-express) (2.8.1)\n",
      "Requirement already satisfied: six in /home/user/conda/lib/python3.7/site-packages (from patsy>=0.5->plotly-express) (1.15.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Using cached retrying-1.3.3-py3-none-any.whl\n",
      "Installing collected packages: retrying, patsy, statsmodels, plotly, plotly-express\n",
      "Successfully installed patsy-0.5.1 plotly-4.14.3 plotly-express-0.4.1 retrying-1.3.3 statsmodels-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly-express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (1.20.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/user/conda/lib/python3.7/site-packages (from seaborn) (1.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/user/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/user/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/user/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/user/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/user/conda/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: six in /home/user/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/user/conda/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.1)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def get_color(number):\n",
    "    color = sns.color_palette(\"deep\")[number]\n",
    "    actual_rgb = tuple(int(255*x) for x in color)\n",
    "    actual_hex = '#%02x%02x%02x' % actual_rgb\n",
    "    return actual_hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_to_string(routes_property):\n",
    "    return [str(int).replace(\"[\", \"\").replace(\"]\", \"\") for int in routes_property]\n",
    "\n",
    "class GIS_processing():\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df_clear = pd.DataFrame()\n",
    "    dfs = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def add_additionals(self, filepath) -> None:\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        route_type = []\n",
    "        start_point_meters = []\n",
    "        finish_point_meters = []\n",
    "        start_point_part = []\n",
    "        finish_point_part = []\n",
    "        instruction_type = []\n",
    "        \n",
    "        for i in tqdm(range(len(self.df[\"drivingDirection_json\"]))):\n",
    "            route_type.append(json.loads(self.df[\"drivingDirection_json\"][i])[\"type\"])\n",
    "            start_point_meters.append(json.loads(self.df[\"drivingDirection_json\"][i])['start_point']['meters'])\n",
    "            finish_point_meters.append(json.loads(self.df[\"drivingDirection_json\"][i])['finish_point']['meters'])\n",
    "            start_point_part.append(json.loads(self.df[\"drivingDirection_json\"][i])['start_point']['part'])\n",
    "            finish_point_part.append(json.loads(self.df[\"drivingDirection_json\"][i])['finish_point']['part'])\n",
    "            if ('instruction' in json.loads(self.df[\"drivingDirection_json\"][i])):\n",
    "                instruction_type.append(json.loads(self.df[\"drivingDirection_json\"][i])['instruction']['type'])\n",
    "            else:\n",
    "                 instruction_type.append(-1)\n",
    "        route_type = pd.DataFrame(cast_to_string(route_type), columns=['route_type'])\n",
    "        start_point_meters = pd.DataFrame(cast_to_string( start_point_meters), columns=['start_point_meters'])\n",
    "        finish_point_meters = pd.DataFrame(cast_to_string(finish_point_meters), columns=['finish_point_meters'])\n",
    "        start_point_part = pd.DataFrame(cast_to_string(start_point_part), columns=[' start_point_part'])\n",
    "        finish_point_part = pd.DataFrame(cast_to_string(finish_point_part), columns=['finish_point_part'])\n",
    "        instruction_type = pd.DataFrame(cast_to_string(instruction_type), columns=['instruction_type'])\n",
    "        \n",
    "        self.df = self.df.join(route_type.join(start_point_meters.join(finish_point_meters.join(start_point_part.join(finish_point_part.join(instruction_type))))))\n",
    "        self.df.to_csv('add_' + Path(filepath).name)\n",
    "        \n",
    "    def flatternize(self, items_column, filepath = \"\", dataframe = \"\",) -> None:\n",
    "        if (filepath == \"\"):\n",
    "            self.df = dataframe\n",
    "        else:\n",
    "            self.df = pd.read_csv(filepath)\n",
    "            \n",
    "        routes_edges = []\n",
    "        routes_time = []\n",
    "        routes_speed = []\n",
    "        routes_length = []\n",
    "#        routes_traffic_type = []\n",
    "\n",
    "        for i in tqdm(range(len(self.df))):\n",
    "            routes_edges.append([])\n",
    "            routes_time.append([])\n",
    "            routes_speed.append([])\n",
    "            routes_length.append([])\n",
    "#            routes_traffic_type.append([])\n",
    "            for j in range(len(json.loads(self.df.iloc[i, items_column])['items'])):\n",
    "                 for k in range(len(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'])):\n",
    "                        routes_edges[i].append(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'][k]['edge_id'])\n",
    "                        routes_time[i].append(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'][k]['time'])\n",
    "                        routes_speed[i].append(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'][k]['speed'])\n",
    "                        routes_length[i].append(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'][k]['length'])\n",
    "#                if ('traffic_type' in json.loads(df.iloc[i, items_column])['items'][j]['edges'][k]):\n",
    "#                            routes_traffic_type[i].append(json.loads(self.df.iloc[i, items_column])['items'][j]['edges'][k]['traffic_type'])\n",
    "#                        else:\n",
    "#                            routes_traffic_type[i].append(-1)\n",
    "                            \n",
    "        edges_pd = pd.DataFrame(cast_to_string(routes_edges), columns=['edges'])\n",
    "        time_pd = pd.DataFrame(cast_to_string(routes_time), columns=['time'])\n",
    "        speed_pd = pd.DataFrame(cast_to_string(routes_speed), columns=['speed'])\n",
    "        routes_length_pd = pd.DataFrame(cast_to_string(routes_length), columns=['length'])\n",
    "#        routes_traffic_type_pd = pd.DataFrame(cast_to_string(routes_traffic_type), columns=['directionality'])\n",
    "        \n",
    "        \n",
    "        self.df = self.df.join(edges_pd.join(time_pd.join(speed_pd.join(routes_length_pd)))).drop(['start_json', 'end_json', 'navigationId', \"start_utc\", \"end_utc\", \"ETA\", \"build_utc\", \"build_timestamp\"], axis=1)\n",
    "        self.df.to_csv('processed_' + Path(filepath).name)\n",
    "        return(self.df)\n",
    "        \n",
    "    def plot_time_freq(self, routes_1, routes_2):\n",
    "        \n",
    "        def freq_counter(routes):\n",
    "            freq = []\n",
    "            time = []\n",
    "            index = pd.DatetimeIndex(routes['start_timestamp'])\n",
    "            for i in range(0, 23):\n",
    "                freq.append(len(routes.iloc[index.indexer_between_time(str(0+i) + ':00', str(1+i) + ':00')]))\n",
    "                time.append(str(0+i) + ':00 - ' +  str(1+i) + ':00');\n",
    "            freq.append(len(routes.iloc[index.indexer_between_time('23:00','00:00')]))\n",
    "            time.append('23:00 - 00:00')\n",
    "            df = pd.DataFrame(freq, index = time, columns = ['frequencies'])\n",
    "            return(df)\n",
    "\n",
    "        def draw_freq_hist(freq_df):\n",
    "            fig = px.bar(freq_df, x=freq_df.index, y='frequencies')\n",
    "            fig.show()\n",
    "\n",
    "        def draw_freq_line(freq_1, freq_2):\n",
    "            fig = px.line(freq_1, x=freq_1.index, y='frequencies')\n",
    "            fig.add_scatter(x=freq_2.index, y=freq_2['frequencies'], mode='lines')\n",
    "            fig.show()\n",
    "            \n",
    "        freq_city_1 = freq_counter(routes_1)\n",
    "        freq_city_2 = freq_counter(routes_2)\n",
    "        \n",
    "        draw_freq_line(freq_city_1, freq_city_2)\n",
    "        \n",
    "    def plot_time_freq(self, routes_1, routes_2):\n",
    "        \n",
    "        def flat_list(data):\n",
    "            return [int(item.replace(\"'\", \"\")) for sublist in data for item in sublist]\n",
    "        \n",
    "        def get_use_data(routes_omsk):\n",
    "            day_edges = [] \n",
    "            for i in range(0, 2):\n",
    "                tmp = routes_omsk[(routes_omsk['start_timestamp'] >= '2020-12-0' + str(7+i)) & (routes_omsk['start_timestamp'] < '2020-12-0' + str(7+i+1))]['new_edges'].to_list()\n",
    "                tmp_cl = [x for x in tmp if str(x) != 'nan']\n",
    "                for j in range(len(tmp_cl)):\n",
    "                    tmp_cl[j] = tmp_cl[j].split(',')\n",
    "                day_edges.append(flat_list(tmp_cl))\n",
    "\n",
    "            tmp = routes_omsk[(routes_omsk['start_timestamp'] >= '2020-12-09') & (routes_omsk['start_timestamp'] < '2020-12-10')]['new_edges'].to_list()\n",
    "            tmp_cl = [x for x in tmp if str(x) != 'nan']\n",
    "            for j in range(len(tmp_cl)):\n",
    "                tmp_cl[j] = tmp_cl[j].split(',')\n",
    "            day_edges.append(flat_list(tmp_cl))\n",
    "\n",
    "            for i in range(0, 4):\n",
    "                tmp = routes_omsk[(routes_omsk['start_timestamp'] >= '2020-12-1' + str(i)) & (routes_omsk['start_timestamp'] < '2020-12-1' + str(i+1))]['new_edges'].to_list()\n",
    "                tmp_cl = [x for x in tmp if str(x) != 'nan']\n",
    "                tmp_cl = [x for x in tmp_cl if str(x) != '']\n",
    "                for j in range(len(tmp_cl)):\n",
    "                    tmp_cl[j] = tmp_cl[j].split(',')\n",
    "                day_edges.append(flat_list(tmp_cl))\n",
    "                return day_edges\n",
    "        \n",
    "        def usage_to_dict(usage):\n",
    "            counts = dict()\n",
    "            for i in usage:\n",
    "                counts[i] = counts.get(i, 0) + 1\n",
    "            return counts\n",
    "\n",
    "        def overall_to_dict(overall):\n",
    "            counts = dict()\n",
    "            for i in overall:\n",
    "                counts[i] = 0\n",
    "            return counts\n",
    "        \n",
    "        def draw_freq_line_inter(freq_1, freq_2, freq_3):\n",
    "            fig = px.line(freq_1, x=freq_1.index, y='frequencies')\n",
    "            fig.add_scatter(x=freq_2.index, y=freq_2['frequencies'], mode='lines', line = {'color': get_color(3), 'dash': 'solid'})\n",
    "            fig.add_scatter(x=freq_3.index, y=freq_3['frequencies'], mode='lines', line = {'color': get_color(8), 'dash': 'solid'})\n",
    "            fig.update_layout(showlegend=False)\n",
    "            fig.show()\n",
    "        \n",
    "        overall = flat_list(dfs[1])\n",
    "        usage_monday = usage_to_dict(get_use_data(routes_omsk_clear)[0])\n",
    "        usage_wednesday = usage_to_dict(get_use_data(routes_omsk_clear)[1])\n",
    "\n",
    "        usage_saturday = usage_to_dict(get_use_data(routes_omsk_clear)[5])\n",
    "        usage_sunday = usage_to_dict(get_use_data(routes_omsk_clear)[6])\n",
    "        overall = overall_to_dict(overall)\n",
    "        \n",
    "        weekdays = {k: overall.get(k, 0) + usage_monday.get(k, 0) + usage_wednesday.get(k, 0) \n",
    "            for k in set(overall) | set(usage_monday) | set(usage_wednesday)}\n",
    "        weekend = {k: overall.get(k, 0) + usage_saturday.get(k, 0) + usage_sunday.get(k, 0) \n",
    "            for k in set(overall) | set(usage_saturday) | set(usage_sunday)}\n",
    "        intersection = {x:min(weekdays[x], weekend[x]) for x in weekdays if x in weekend}\n",
    "        \n",
    "        weekdays = pd.DataFrame.from_dict(weekdays, orient = 'index', columns = ['frequencies']).reset_index()\n",
    "        weekend = pd.DataFrame.from_dict(weekend, orient = 'index', columns = ['frequencies']).reset_index()\n",
    "        intersection = pd.DataFrame.from_dict(intersection, orient = 'index', columns = ['frequencies']).reset_index()\n",
    "        \n",
    "        draw_freq_line_inter(intersection, weekdays, weekend)\n",
    "        \n",
    "        \n",
    "    def clear_flatternized(self, filepath = None) -> None:\n",
    "\n",
    "        def del_heads_n_tails(route):\n",
    "            counter_d = 0\n",
    "            edge_arr = route['edges'].split(',')\n",
    "            time_arr = route['time'].split(',')\n",
    "            speed_arr = route['speed'].split(',')\n",
    "            len_arr = route['length'].split(',')\n",
    "#            dir_arr = route['directionality'].split(',')\n",
    "            \n",
    "            indexes = []\n",
    "            for j in range(len(edge_arr)):\n",
    "                if (int(edge_arr[j]) == 0 or int(time_arr[j]) == 0):\n",
    "                    indexes.append(j)\n",
    "\n",
    "            for j in range(len(edge_arr) - 1):\n",
    "                if (int(edge_arr[j]) == int(edge_arr[j+1])):\n",
    "                    indexes.append(j)\n",
    "\n",
    "            indexes = set(indexes)\n",
    "            counter_d = len(indexes)\n",
    "            for index in sorted(indexes, reverse=True):\n",
    "                del edge_arr[index]\n",
    "                del time_arr[index]\n",
    "                del speed_arr[index]\n",
    "                del len_arr[index]\n",
    "#                del dir_arr[index]                                                             \n",
    "            \n",
    "            return [edge_arr, time_arr, speed_arr, len_arr, counter_d]\n",
    "\n",
    "        def clear_routes_data(routes):\n",
    "            edges_clear = []\n",
    "            time_clear = []\n",
    "            speed_clear = []\n",
    "            len_clear = []\n",
    " #           dir_clear = []\n",
    "                                                                                     \n",
    "            counter_do = 0\n",
    "            for i in tqdm(range(len(routes))):\n",
    "                route_data = del_heads_n_tails(routes.iloc[i, :])\n",
    "                edges_clear.append(route_data[0])\n",
    "                time_clear.append(route_data[1])\n",
    "                speed_clear.append(route_data[2])\n",
    "                len_clear.append(route_data[3])\n",
    "#                dir_clear.append(route_data[4])\n",
    "                counter_do += route_data[4] \n",
    "            routes_properties = [[edges_clear, 'edges'], [time_clear, 'time'], [speed_clear, 'speed'], [len_clear, 'length']]\n",
    "            for i in range(len(routes_properties)):\n",
    "                routes_properties[i] = pd.DataFrame(cast_to_string(routes_properties[i][0]), columns = [routes_properties[i][1]])\n",
    "            return [routes_properties, edges_clear, counter_do]\n",
    "        \n",
    "        if (filepath != None):\n",
    "            self.dfs = clear_routes_data(pd.read_csv(filepath))\n",
    "            self.df = pd.read_csv(filepath)\n",
    "        else:          \n",
    "            self.dfs = clear_routes_data(self.df)\n",
    "#        self.df_clear = self.df.drop(['edges', 'time', 'speed', 'length', 'directionality'], axis=1).join(self.dfs[0][0].join(self.dfs[0][1].join(self.dfs[0][2].join(self.dfs[0][3].join(self.dfs[0][4])))))\n",
    "        self.df_clear = self.df.drop(['edges', 'time', 'speed', 'length'], axis=1).join(self.dfs[0][0].join(self.dfs[0][1].join(self.dfs[0][2].join(self.dfs[0][3]))))\n",
    "        self.df_clear.to_csv('clear_' + Path(filepath).name)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_period(routes):\n",
    "    index = pd.DatetimeIndex(routes['start_timestamp'])\n",
    "    routes['day_period'] = -1\n",
    "    routes.loc[index.indexer_between_time('00:00', '06:00'), 'day_period'] = 0\n",
    "    routes.loc[index.indexer_between_time('06:00', '11:00'), 'day_period'] = 1\n",
    "    routes.loc[index.indexer_between_time('11:00', '19:00'), 'day_period'] = 2\n",
    "    routes.loc[index.indexer_between_time('19:00', '00:00'), 'day_period'] = 3\n",
    "    return routes\n",
    "\n",
    "def week_period(clear): # that's hell, i know\n",
    "    clear['week_period'] = -1\n",
    "    clear.loc[('2021-01-01' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2021-01-02'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-31' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2021-01-01'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-30' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-31'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-29' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-30'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-28' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-29'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-27' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-28'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-26' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-27'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-25' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-26'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-24' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-25'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-23' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-24'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-22' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-23'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-21' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-22'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-20' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-21'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-19' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-20'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-18' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-19'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-17' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-18'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-16' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-17'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-15' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-16'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-14' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-15'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-13' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-14'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-12' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-13'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-11' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-12'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-10' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-11'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-09' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-10'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-08' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-09'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-07' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-08'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-06' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-07'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-05' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-06'), 'week_period'] = 1\n",
    "    clear.loc[('2020-12-04' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-15'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-03' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-04'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-02' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-03'), 'week_period'] = 0\n",
    "    clear.loc[('2020-12-01' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-02'), 'week_period'] = 0\n",
    "    clear.loc[('2020-11-30' <= clear['start_timestamp']) & (clear['start_timestamp'] <= '2020-12-01'), 'week_period'] = 0\n",
    "    return clear\n",
    "\n",
    "def weather_period(clear, prop, values):\n",
    "    clear[prop] = -1    \n",
    "    \n",
    "    night = pd.DatetimeIndex(clear['start_timestamp']).indexer_between_time('00:00', '11:00')\n",
    "    day = pd.DatetimeIndex(clear['start_timestamp']).indexer_between_time('11:00', '19:00')\n",
    "    evening = pd.DatetimeIndex(clear['start_timestamp']).indexer_between_time('19:00', '06:00')\n",
    "    parts = [night, day, evening]\n",
    "    v_index = 0\n",
    "    dates = ['2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-05', '2020-12-06','2020-12-07', '2020-12-08', \n",
    "             '2020-12-09', '2020-12-10', '2020-12-11', '2020-12-12', '2020-12-13', '2020-12-14', '2020-12-15', '2020-12-16', '2020-12-17',\n",
    "             '2020-12-18', '2020-12-19', '2020-12-20', '2020-12-21', '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25', '2020-12-26', \n",
    "             '2020-12-27', '2020-12-28', '2020-12-29', '2020-12-30', '2020-12-31'] # and this is too \n",
    "    for j in range(len(dates) - 1):\n",
    "        for i in range(len(parts)):\n",
    "            s = (dates[j] <= clear.loc[parts[i], 'start_timestamp']) & (clear.loc[parts[i], 'start_timestamp'] <= dates[j+1])\n",
    "            clear.loc[(s)[s].index, prop] = values[v_index]\n",
    "            if (i+2 != len(parts)):\n",
    "                v_index += 1\n",
    "\n",
    "    return clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = GIS_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"574880_omsk_routes_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_const = 20898 # near to optimal for 24 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spawn():\n",
    "    dataframe_list = []\n",
    "    procs = list()\n",
    "    n_cpus = psutil.cpu_count()\n",
    "    manager = mp.Manager()\n",
    "    return_list = manager.list()\n",
    "    \n",
    "    for cpu in range(37):\n",
    "        d = dict(border = part_const*(cpu+1))\n",
    "        p = mp.Process(target=run_child, args=(d, return_list))\n",
    "        p.start()\n",
    "        procs.append(p)\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "        print('joined')\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "def run_child(border, return_list):\n",
    "    print(border['border'])\n",
    "    df = pd.DataFrame(dataframe[(int(border['border'])-part_const):border['border']]).reset_index()\n",
    "    return_list.append([(int(border['border'])-part_const)/part_const,processing.flatternize(16, filepath = \"\", dataframe = df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20898\n",
      "4179662694\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83592"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/20898 [00:00<18:04, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/20898 [00:00<16:38, 20.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "125388146286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/20898 [00:03<3:29:59,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/20898 [00:03<2:33:11,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188082"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/20898 [00:01<10:51, 32.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "208980229878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/20898 [00:06<6:44:16,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/20898 [00:07<4:50:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271674292572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/20898 [00:06<2:31:58,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313470\n",
      "334368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/20898 [00:10<9:26:04,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/20898 [00:03<32:25, 10.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/20898 [00:11<8:41:16,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376164397062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/20898 [00:04<56:16,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438858\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/20898 [00:12<5:26:40,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459756480654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/20898 [00:17<14:22:39,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "501552"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/20898 [00:10<8:06:45,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "543348"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/20898 [00:19<13:15:45,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "564246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "585144606042\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/20898 [00:12<18:23:21,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/20898 [00:07<39:33,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647838668736"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "689634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/20898 [00:23<11:12:14,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "710532\n",
      "731430"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20898 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/20898 [00:29<21:27:17,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/20898 [00:11<34:08, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20898/20898 [1:36:04<00:00,  3.63it/s]  \n",
      "100%|██████████| 20898/20898 [1:37:03<00:00,  3.59it/s]  \n",
      "100%|██████████| 20898/20898 [1:37:05<00:00,  3.59it/s]\n",
      "100%|██████████| 20898/20898 [1:37:37<00:00,  3.57it/s]\n",
      "100%|██████████| 20898/20898 [1:37:17<00:00,  3.58it/s]\n",
      "100%|██████████| 20898/20898 [1:38:03<00:00,  3.55it/s]\n",
      "100%|██████████| 20898/20898 [1:38:12<00:00,  3.55it/s]\n",
      "100%|██████████| 20898/20898 [1:38:33<00:00,  3.53it/s]\n",
      "100%|██████████| 20898/20898 [1:38:43<00:00,  3.53it/s]\n",
      "100%|██████████| 20898/20898 [1:38:55<00:00,  3.52it/s]\n",
      "100%|██████████| 20898/20898 [1:39:15<00:00,  3.51it/s]\n",
      "100%|██████████| 20898/20898 [1:39:16<00:00,  3.51it/s]\n",
      "100%|██████████| 20898/20898 [1:39:22<00:00,  3.51it/s]\n",
      "100%|██████████| 20898/20898 [1:39:59<00:00,  3.48it/s]\n",
      "100%|██████████| 20898/20898 [1:40:04<00:00,  3.48it/s]\n",
      "100%|██████████| 20898/20898 [1:40:22<00:00,  3.47it/s]\n",
      "100%|██████████| 20898/20898 [1:40:31<00:00,  3.47it/s]\n",
      "100%|██████████| 20898/20898 [1:40:30<00:00,  3.47it/s]\n",
      "100%|██████████| 20898/20898 [1:41:15<00:00,  3.44it/s]\n",
      " 97%|█████████▋| 20362/20898 [1:40:57<00:59,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20898/20898 [1:41:08<00:00,  3.44it/s]\n",
      "100%|██████████| 20898/20898 [1:41:06<00:00,  3.44it/s]\n",
      "100%|██████████| 20898/20898 [1:41:14<00:00,  3.44it/s]\n",
      "100%|██████████| 20898/20898 [1:41:50<00:00,  3.42it/s]\n",
      "100%|██████████| 20898/20898 [1:41:33<00:00,  3.43it/s]\n",
      "100%|██████████| 20898/20898 [1:41:28<00:00,  3.43it/s]\n",
      "100%|██████████| 20898/20898 [1:41:58<00:00,  3.42it/s]\n",
      "100%|██████████| 20898/20898 [1:41:48<00:00,  3.42it/s]\n",
      "100%|██████████| 20898/20898 [1:41:44<00:00,  3.42it/s]\n",
      "100%|██████████| 20898/20898 [1:41:48<00:00,  3.42it/s]\n",
      "100%|██████████| 20898/20898 [1:42:09<00:00,  3.41it/s]\n",
      "100%|██████████| 20898/20898 [1:42:19<00:00,  3.40it/s]\n",
      "100%|██████████| 20898/20898 [1:42:19<00:00,  3.40it/s]\n",
      "100%|██████████| 20898/20898 [1:42:27<00:00,  3.40it/s]\n",
      "100%|██████████| 20898/20898 [1:42:39<00:00,  3.39it/s]\n",
      "100%|██████████| 20898/20898 [1:43:09<00:00,  3.38it/s]\n",
      "100%|██████████| 20898/20898 [1:42:55<00:00,  3.38it/s]\n",
      " 99%|█████████▉| 20718/20898 [1:42:57<00:32,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 20730/20898 [1:43:00<00:34,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20898/20898 [1:43:26<00:00,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n",
      "joined\n"
     ]
    }
   ],
   "source": [
    "a = spawn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [01:04<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "normal_container_s = []\n",
    "for i in tqdm(range(len(a))):\n",
    "    normal_container_s.append(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_s_s = sorted(normal_container_s,key=lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = a_s_s[0][1]\n",
    "for i in range(1, len(a_s_s)):\n",
    "    result = result.append(a_s_s[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"processed_omsk_E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773226/773226 [24:36<00:00, 523.86it/s]\n"
     ]
    }
   ],
   "source": [
    "processing.add_additionals('processed_omsk_E.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "!rm processed_omsk_E.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 773226/773226 [04:06<00:00, 3137.30it/s]\n"
     ]
    }
   ],
   "source": [
    "processing.clear_flatternized(\"add_processed_omsk_E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = pd.read_csv(\"clear_add_processed_omsk_E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_dates = week_period(day_period(clear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-7997c910f5aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclear_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"omsk_full_routes_final.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m         )\n\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         )\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m             )\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_native_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mlibwriters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mpandas/_libs/writers.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clear_dates.to_csv(\"omsk_full_routes_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "december_omsk = pd.read_csv(\"omsk_december_fixed.csv\", sep = \";\")\n",
    "clouds_omsk_day = december_omsk[\"cloud\"].to_list()\n",
    "snow_omsk_day = december_omsk[\"weather\"].to_list()\n",
    "temp_omsk_day = december_omsk[\"temp\"].to_list()\n",
    "wind_omsk_day = december_omsk[\"windDir(from)\"].to_list()\n",
    "press_omsk_day = december_omsk[\"pressure\"].to_list() \n",
    "clouds_omsk_night = december_omsk[\"cloud.1\"].to_list()\n",
    "snow_omsk_night = december_omsk[\"weather.1\"].to_list()\n",
    "temp_omsk_night = december_omsk[\"temp.1\"].to_list()\n",
    "wind_omsk_night = december_omsk[\"windDir(from).1\"].to_list()\n",
    "press_omsk_night = december_omsk[\"pressure.1\"].to_list()\n",
    "\n",
    "def weather_merger(day, night):\n",
    "    result = []\n",
    "    for i in range(len(day)):\n",
    "        result.append(day[i])\n",
    "        result.append(night[i])\n",
    "    return result\n",
    "\n",
    "clouds_omsk = weather_merger(clouds_omsk_day, clouds_omsk_night)\n",
    "snow_omsk = weather_merger(snow_omsk_day, snow_omsk_night)\n",
    "temp_omsk = weather_merger(temp_omsk_day, temp_omsk_night)\n",
    "wind_omsk = weather_merger(wind_omsk_day, wind_omsk_night)\n",
    "press_omsk = weather_merger(press_omsk_day, press_omsk_night)\n",
    "\n",
    "props = ['clouds', 'snow', 'temperature', 'wind', 'pressure']\n",
    "vals_omsk = [clouds_omsk, snow_omsk, temp_omsk, wind_omsk, press_omsk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"omsk_full_routes_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop(final.loc[('2020-11-31' <= final['start_timestamp']) & (final['start_timestamp'] <= '2020-12-01')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop(final.loc[('2021-01-01' <= final['start_timestamp']) & (final['start_timestamp'] <= '2021-01-02')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(props))):\n",
    "    final = weather_period(final, props[i], vals_omsk[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop([\"instruction_type\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"omsk_full_routes_final_weather.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
